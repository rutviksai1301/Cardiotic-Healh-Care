---
title: "Untitled"
output: word_document
date: "2024-04-12"
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction
Advanced analytical techniques are becoming more important for guiding cardiotocographic decisions in healthcare. Practitioners can use strong prediction models to enhance treatment efficacy and diagnostic accuracy while navigating complex patient care. However, because medical problems are complex and there is a large amount of data, it is difficult to distinguish the signal from noise. The problem is particularly relevant to cardiotocography (CTG), a key obstetric care treatment. Regression analysis, a fundamental statistical tool, allows you to discover complicated correlations hidden in CTG data. The CTG analysis aimed to clarify the regression analysis in this study. Using the data generated by the cardiotocographic recorder. Extreme gradient boosting (XGBoost), a machine learning technique noted for its prediction skills, uses a dataset. This study aims to create a prediction model that can differentiate between suspicious, pathogenic, and normal CTG traces to improve baby outcomes and allow for prompt treatment interventions. Through a careful combination of theoretical insights and practical implementations, I hope to provide data scientists and medical professionals with the knowledge and skills they need to traverse the complexities of regression analysis in healthcare successfully. 

# Materil and Method

## Load the data set
Before model building process, first load the data set in R and save the data set as a df. The top five rows and structure of the data set was checked by using the head and str function of R. While to better understand the data set, the descriptive statistics was accessed by using the summary function.
```{r}
library(readr)
df <- read_csv("cardiotocographic.csv")
head(df)
str(df)
summary(df)
```

## Split the data
The data set was splitted into the 20 and 80 percent. Our train data set have 1700 observations while test data have 426 observations with 22 columns.
```{r}
# Set seed and split the data into training and testing sets (80:20)
set.seed(123)
train_index <- sample(nrow(df), 0.8 * nrow(df))
train_data <- df[train_index, ]
test_data <- df[-train_index, ]
dim(train_data)
dim(test_data)
```

## Prepare the Data for model
In this process first create a model matrix for train and test data set and our dependent variable was saved  separately into y train and test data.
```{r}
X_train <- as.matrix(train_data[, -ncol(train_data)])
y_train <- train_data$NSP
X_test <- as.matrix(test_data[, -ncol(test_data)])
y_test <- test_data$NSP
```

# XGBoost model
After training on three classes and a multi-class classification goal, the XGBoost model underwent one hundred iterations to refine its parameters and improve its prediction capability. The multi-class logarithmic loss metric to assess the model's performance during training. This metric evaluates the degree to which predicted probability conforms with actual class labels. When the model started to perform less than optimally, it showed significant loss numbers. However, as the iteration continued, the loss progressively dropped, demonstrating the model's increasing ability to make precise predictions. The logarithmic loss significantly decreased to an exceptionally low value at the 100th iteration, indicating that the model has successfully and precisely recognized occurrences within the dataset. The incremental increase shows how well the XGBoost approach enhances model performance and how well it can handle challenging predictive modeling jobs. 

```{r}
# Load necessary libraries
library(xgboost)
# Train the XGBoost model
xgb_model <- xgboost(data = X_train, label = (y_train) - 1, nrounds = 100, objective = "multi:softmax", num_class = 3)
xgb_model
```


## Model Prediction and Performance
The confusion matrix provides information on the model's classification overall performance by showing the wide variety of real high-quality, false high-quality, and fake terrible predictions for every elegance. The accuracy of the model changed to around 95.54%. Class 1 (suspect) has an extremely decreased sensitivity of 79.66% compared to Class Zero, with the highest sensitivity of 98.46% and 95.24 % for Class 2 (pathologic). 
The model's specificity ratings of 88% and 98% demonstrate how well it recognizes occurrences that do not fall into either Class 1 or Class 2. The real negative rate for each class is known as specificity. 

For every class, the positive predictive value ranges from 90% to 96% and shows the percentage that separates the model's actual positive forecasts from its predictions. 

Among the model's negative predictions or negative predictive value, 94%-99% are actual negative forecasts. 

The most prevalent class is 0, with 76.29% of all occurrences in the dataset. 

Prevalence displays the proportion of occurrences in a particular class; Class 0 (419.45) has the highest detection rate, and Class 2 (405.71) is followed by Class 1 (339.36). 

The average number of successfully identified instances per class is known as the detection rate; class 0 has the highest detection prevalence, at 77.93%. 

The balanced accuracy calculates the average sensitivity and specificity across classes as a final indicator of the model's overall efficacy and accuracy at 93.27%. Combined, these metrics provide a comprehensive evaluation of the model's classification performance and accuracy in predicting the various fetal state categories in the dataset. 

```{r}
# Make predictions
predictions <- predict(xgb_model, X_test)
# Evaluate the model
confusion_matrix <- table(Actual = as.numeric(y_test) - 1, Predicted = predictions)
confusion_matrix
# Calculate statistics
n <- sum(confusion_matrix)
n_correct <- sum(diag(confusion_matrix))
n_classes <- nrow(confusion_matrix)
# Calculate accuracy
accuracy <- n_correct / n
accuracy
# Calculate sensitivity for each class
sensitivity <- diag(confusion_matrix) / rowSums(confusion_matrix, na.rm = TRUE)
sensitivity
# Calculate specificity for each class
specificity <- rep(NA, n_classes)
for (i in 1:n_classes) {
  specificity[i] <- sum(confusion_matrix[-i, -i]) / sum(confusion_matrix[-i, ])
}
specificity
# Calculate positive predictive value (PPV) for each class
ppv <- diag(confusion_matrix) / colSums(confusion_matrix, na.rm = TRUE)
ppv
# Calculate negative predictive value (NPV) for each class
npv <- rep(NA, n_classes)
for (i in 1:n_classes) {
  npv[i] <- sum(confusion_matrix[-i, -i]) / sum(confusion_matrix[, -i])
}
npv
# Calculate prevalence for each class
prevalence <- rowSums(confusion_matrix) / n
prevalence
# Calculate detection rate (sensitivity) for each class
detection_rate <- diag(confusion_matrix) / prevalence
detection_rate
# Calculate detection prevalence for each class
detection_prevalence <- colSums(confusion_matrix) / n
detection_prevalence
# Calculate balanced accuracy
balanced_accuracy <- mean(c(sensitivity, specificity), na.rm = TRUE)
balanced_accuracy
```

## Importance
The features of the XGBoost model provide valuable information about the factors influencing the model's prediction accuracy. The three most crucial elements to consider when assessing any feature are gain, coverage, and frequency. The gain displays the average contribution of each feature to raising the accuracy of the model throughout training. The rise in MSTV (Mean Short Term Variability) of around 16.85% is the main factor. It suggests that the modifications made to the MSTV have a significant impact on the scenario identification model's accuracy. Following with an improvement of over 16.00% and 14.53%, respectively, ASTV (percentage of time with aberrant short-term variability) and mean value show their important contribution to model performance. Based on the observational coverage of the data set, cover determines the relative significance of each characteristic. The fact that ASTV has drawn the most attention demonstrates how frequent and significant it is to fully represent a dataset's variety. Each attribute's frequency denotes how often the file use it to build the decision tree. They are important because of the ubiquity of the umbilical cord (UC) and anomalous long-term variability (ALTV) in the differentiation of prenatal diseases. Our findings emphasize the significance of differentiating between hazardous, suspicious, and normal fetal states based on certain CTG traits; this categorization may help with clinical decision-making in obstetrics. Healthcare practitioners may enhance maternal health and pregnancy outcomes by selecting treatments and interventions according to the relative importance of these parameters.
```{r}
importance <- xgb.importance (feature_names = colnames(X_test),model = xgb_model)
importance
xgb.plot.importance (importance_matrix = importance)
```

